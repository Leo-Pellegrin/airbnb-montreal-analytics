# ğŸ¡Â MontrÃ©al Airbnb Analytics Dashboard

**Analyse de donnÃ©es + DashboardÂ fullâ€‘stack**  
DonnÃ©es brutes â†’ ETL Python â†’ PostgreSQLâ€¯(Supabase) â†’ API FastAPI â†’ Front NuxtÂ 3

---

## ğŸ“‘Â Sommaire
1. [PrÃ©requis](#prÃ©requis)
2. [Structure du dÃ©pÃ´t](#structure-du-dÃ©pÃ´t)
3. [PipelineÂ ETL](#pipeline-etl)
4. [Analyse exploratoire (EDA)](#analyse-exploratoire-eda)
5. [StackÂ technique](#stack-technique)
6. [Lancement rapide](#lancement-rapide)
7. [RoadÂ Map](#road-map)
8. [Licence](#licence)

---

## PrÃ©requis
- **PythonÂ 3.10+**Â (`pipx` conseillÃ©)
- **NodeÂ 18+** (NuxtÂ 3, pnpm)
- **SupabaseÂ CLI**Â (`npmÂ iÂ -gÂ supabase`)
- `psql` (ou DockerÂ +Â pgcli)
- ComptesÂ : Supabase, Vercel

## Structure du dÃ©pÃ´t

â”œâ”€ clean/                   # CSV nettoyÃ©s prÃªts Ã  lâ€™import
â”œâ”€ notebooks/               # EDA Jupyter
â”œâ”€ scripts/
â”‚   â”œâ”€ key_columns_finder.py     # dÃ©tection colonnes clÃ© (PK) dans CSV bruts
â”‚   â”œâ”€ clean_data.py             # pipeline de nettoyage initial
â”‚   â”œâ”€ assign_neighbourhoods.py  # jointure spatiale â†’ quartier
â”‚   â”œâ”€ validate_clean_data.py    # contrÃ´les qualitÃ© avant import
â”‚   â””â”€ import_airbnb_supabase.sh # import CSV â†’ Supabase (optionnel
â”œâ”€ backend/                 # FastAPI (src/)
â”œâ”€ frontend/                # Nuxt 3 (app/)
â””â”€ README.md

## PipelineÂ ETLÂ &Â QualitÃ©

| Ã‰tape | Script / commande | RÃ©sultat |
|-------|-------------------|----------|
| 1 | `python scripts/key_columns_finder.py ./raw_data` | VÃ©rifie unicitÃ© & clÃ©s candidates |
| 2 | `python scripts/clean_data.py` | GÃ©nÃ¨re `clean/*_clean.csv` |
| 3 | `python scripts/assign_neighbourhoods.py` | Ajoute `neighbourhood` manquants â†’ `listings_clean_geo.csv` |
| 4 | `python scripts/validate_clean_data.py ./clean` | ContrÃ´le intÃ©gritÃ© / valeur manquante **0** |
| 5 | `PGURL=... ./scripts/import_airbnb_supabase.sh` *(ou `\COPY` via psql)* | Charge les donnÃ©es dans Supabase |

> AprÃ¨s lâ€™Ã©tapeÂ 4, la sortie doit afficher `neighbourhoodÂ : 0` et `id en doubleÂ : 0`.  
> Lâ€™import (Ã©tapeÂ 5) est optionnel, on peut utiliser `COPY FROM 'supabase://...'` dans le SQLÂ Editor.

## Analyse exploratoire (EDA)
Les notebooks `notebooks/eda_*.ipynb` couvrentÂ :
- Structure & qualitÃ©
- Distribution des prix
- Prix par quartier
- SaisonnalitÃ©, corrÃ©lations, sentiment des avis
- Carte choroplÃ¨the quartiers

## StackÂ technique
| Couche | Techno |
|--------|--------|
| BaseÂ deÂ donnÃ©es | **PostgreSQLÂ 15** (Supabase pooler) |
| Backend | **FastAPI** + asyncpg |
| Frontend | **NuxtÂ 3** + VueÂ 3 + Chart.js |
| Auth | Supabase Auth (JWT) |
| DÃ©ploiement | Vercel (front) / RenderÂ ouÂ Railway (API) |

## Lancement rapide
```bash
# 1. Cloner le repo & installer Python env
git clone https://github.com/Leo-Pellegrin/airbnb-montreal-analytics.git
cd airbnb-montreal-analytics
pipx runpip python -e . '[dev]'

# 2. Nettoyage + ajout quartiers + validation
python scripts/key_columns_finder.py ./raw_data
python scripts/clean_data.py
python scripts/assign_neighbourhoods.py
python scripts/validate_clean_data.py ./clean

# 3. Import (Supabase)
PGURL="postgresql://user:pw@host:6543/postgres?sslmode=require" \
./scripts/import_airbnb_supabase.sh

# 3. Frontend
cd frontend && pnpm i && pnpm dev

# 4. Backend
cd backend && uvicorn app.main:app --reload
```

## RoadÂ Map

La feuille de route dÃ©taillÃ©e se trouve dans notebooks/roadmap_eda.md.

## Licence

MIT Â©â€¯2025 LÃ©oÂ Pellegrin